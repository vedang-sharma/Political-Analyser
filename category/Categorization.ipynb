{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5949925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1135415c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the data of Manifesto\n",
    "with open('2004.xml', encoding = 'utf-8') as file_obj:\n",
    "    df = pd.DataFrame(file_obj.readlines(), columns = ['sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aef85a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Don't do this, this was my mistake\n",
    "df.drop(df.index[[0, 918]], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39def2c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manifesto: NDA AN AGENDA FOR DEVELOPMENT, GOOD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It was re-elected in 1999.\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences\n",
       "1  Manifesto: NDA AN AGENDA FOR DEVELOPMENT, GOOD...\n",
       "2                       It was re-elected in 1999.\\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(drop = True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21abbe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatization\n",
    "corpus = np.array([])\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for i in range(len(df['sentences'])):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', df['sentences'][i+1])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [lemmatizer.lemmatize(word) for word in review if word not in set(stopwords.words('English'))] #Lemmatization of each word is done here\n",
    "    \n",
    "    corpus = np.append(corpus, ' '.join(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f8b52ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a3d1ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>aawas</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abhiyan</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abolish</th>\n",
       "      <th>abroad</th>\n",
       "      <th>academic</th>\n",
       "      <th>accelerated</th>\n",
       "      <th>accelerating</th>\n",
       "      <th>...</th>\n",
       "      <th>yielding</th>\n",
       "      <th>yoga</th>\n",
       "      <th>yojana</th>\n",
       "      <th>young</th>\n",
       "      <th>youngest</th>\n",
       "      <th>youth</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zero</th>\n",
       "      <th>zonal</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 2624 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  aawas abandoned abhiyan ability able abolish abroad academic accelerated  \\\n",
       "0   0.0       0.0     0.0     0.0  0.0     0.0    0.0      0.0         0.0   \n",
       "1   0.0       0.0     0.0     0.0  0.0     0.0    0.0      0.0         0.0   \n",
       "\n",
       "  accelerating  ... yielding yoga yojana young youngest youth zealand zero  \\\n",
       "0          0.0  ...      0.0  0.0    0.0   0.0      0.0   0.0     0.0  0.0   \n",
       "1          0.0  ...      0.0  0.0    0.0   0.0      0.0   0.0     0.0  0.0   \n",
       "\n",
       "  zonal zone  \n",
       "0   0.0  0.0  \n",
       "1   0.0  0.0  \n",
       "\n",
       "[2 rows x 2624 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the model and storing the values as a Data Frame\n",
    "model = TfidfVectorizer()\n",
    "X = model.fit_transform(corpus)\n",
    "\n",
    "#Converting the 'X' into a Dataframe\n",
    "data = pd.DataFrame(X.toarray(), columns = [model.get_feature_names_out()])\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "888377d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating numpy array for keywords\n",
    "tokens = []\n",
    "names = ['Education', 'Infrastructure', 'Agriculture', 'Health', 'Economics']\n",
    "\n",
    "for i in range(5):\n",
    "    name = names[i]+'.txt'\n",
    "    with open(name, 'r', encoding = 'utf-8') as file_obj:\n",
    "        text = file_obj.readlines()\n",
    "        words = []\n",
    "        #Removing the '\\n' and appending the new keywords to the new numpy array\n",
    "        for j in text: words.append(re.sub('\\\\n', '', j))\n",
    "        words = np.array(words)\n",
    "        tokens.append(words)\n",
    "        \n",
    "tokens = np.array(tokens, dtype = np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1dc2fe22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Lemmatizing the keywords for easier matching\n",
    "for i in range(len(tokens)):\n",
    "    for j in range(len(tokens[i])):\n",
    "        tokens[i][j] = re.sub('[^a-zA-Z]', ' ', tokens[i][j]) #Removing unnecessary characters from the word\n",
    "        tokens[i][j] = lemmatizer.lemmatize(tokens[i][j].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5f3e2d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "finale = [] #List to store all the TF - IDF values of a sentence\n",
    "\n",
    "for i in range(len(corpus)):\n",
    "    \n",
    "    #TF - IDF values are stored for each sentence here\n",
    "    val = [-1, [0], [0], [0], [0], [0]]\n",
    "    \n",
    "    for word in corpus[i].split():\n",
    "        if word in set(tokens[0]): val[1].append(data[word].iloc[i][0])\n",
    "        if word in set(tokens[1]): val[2].append(data[word].iloc[i][0])\n",
    "        if word in set(tokens[2]): val[3].append(data[word].iloc[i][0])\n",
    "        if word in set(tokens[3]): val[4].append(data[word].iloc[i][0])\n",
    "        if word in set(tokens[4]): val[5].append(data[word].iloc[i][0])\n",
    "    \n",
    "    val[0] = i\n",
    "    \n",
    "    for i in range(1, 6):\n",
    "        if sum(val[i]): val[i] = sum(val[i])/len(val[i])\n",
    "        else: val[i] = 0\n",
    "            \n",
    "    finale.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "90e901aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['sno', 'edu', 'infra', 'agri', 'hea', 'eco']\n",
    "finale = pd.DataFrame(finale, columns = names)\n",
    "\n",
    "finale.to_csv('2004_data.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
